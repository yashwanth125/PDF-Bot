{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c425f155",
        "outputId": "11d85b91-cd3d-45d4-b87f-f2aaed2aebe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.6.13)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.7)\n",
            "Requirement already satisfied: langchain>=0.0.154 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.0.181)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.27.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.26.15)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.5.0)\n",
            "Requirement already satisfied: typing-inspect==0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect==0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (4.0.2)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama_index) (2.27.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama_index) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama_index) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.154->llama_index) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.154->llama_index) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.181)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.15)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.6.10-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argilla (from unstructured)\n",
            "  Downloading argilla-1.7.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Collecting msg-parser (from unstructured)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Collecting pdfminer.six (from unstructured)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Collecting pypandoc (from unstructured)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.27.1)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Collecting httpx<0.24,>=0.15 (from argilla->unstructured)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (23.1)\n",
            "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.10.7)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Collecting backoff (from argilla->unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting monotonic (from argilla->unstructured)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting rich<=13.0.1 (from argilla->unstructured)\n",
            "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (40.0.2)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured)\n",
            "  Downloading XlsxWriter-3.1.1-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
            "Building wheels for collected packages: python-docx, python-pptx, olefile\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=df6ac0864f3196eaafbb1d77cf7d1d1f3750af60a62791369aa3d42fc5ed36e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=47e35b8207f00d9d2636a210a1bad9931bc1ca3ab018f29938645e8b2b84a386\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=7641d8255d828c72a2613f8c5339374a78e4e755b397fc889fdfab83459b995d\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built python-docx python-pptx olefile\n",
            "Installing collected packages: rfc3986, monotonic, commonmark, XlsxWriter, rich, python-magic, python-docx, pypandoc, olefile, h11, deprecated, backoff, python-pptx, msg-parser, httpcore, pdfminer.six, httpx, argilla, unstructured\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "Successfully installed XlsxWriter-3.1.1 argilla-1.7.0 backoff-2.2.1 commonmark-0.9.1 deprecated-1.2.14 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 monotonic-1.6 msg-parser-1.2.0 olefile-0.46 pdfminer.six-20221105 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 rfc3986-1.5.0 rich-13.0.1 unstructured-0.6.10\n"
          ]
        }
      ],
      "source": [
        "!pip install llama_index\n",
        "!pip install pypdf\n",
        "!pip install langchain\n",
        "!pip install unstructured"
      ],
      "id": "c425f155"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec6395b7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Load you data into 'Documents' a custom type by LlamaIndex\n",
        "\n",
        "from llama_index import SimpleDirectoryReader\n",
        "# Create an index of your documents\n",
        "from llama_index import GPTVectorStoreIndex\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ],
      "id": "ec6395b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65a0e830"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self, api_key, index):\n",
        "        self.index = index\n",
        "        openai.api_key = api_key\n",
        "        self.chat_history = []\n",
        "\n",
        "    def generate_response(self, user_input):\n",
        "        prompt = \"\\n\".join([f\"{message['role']}: {message['content']}\" for message in self.chat_history[-5:]])\n",
        "        prompt += f\"\\nUser: {user_input}\"\n",
        "        query_engine = index.as_query_engine()\n",
        "        response = query_engine.query(user_input)\n",
        "\n",
        "        message = {\"role\": \"assistant\", \"content\": response.response}\n",
        "        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        self.chat_history.append(message)\n",
        "        return message\n",
        "    \n",
        "    def load_chat_history(self, filename):\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                self.chat_history = json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "\n",
        "    def save_chat_history(self, filename):\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.chat_history, f)\n"
      ],
      "id": "65a0e830"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0d3da1c"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader('./data').load_data()\n",
        "index = GPTVectorStoreIndex.from_documents(documents)\n",
        "\n"
      ],
      "id": "a0d3da1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24576df3",
        "outputId": "1826860e-eeca-4156-ab9a-96862c7fce77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: what are the  engineering features\n",
            "Bot: \n",
            "Engineering features are features that are applied directly to the model without the need for a sketch. Examples of engineering type features are rounds, chamfers, holes, draft features, and so on.\n",
            "You: how to authenticate user access\n",
            "Bot: \n",
            "To authenticate user access, you must type your username in the format <user name@ptc.com> in the Username textbox, type the corresponding password in the Password textbox, and click Log In. If you do not remember your username or password, you can click Reset my password to be redirected to a page on PTC.com to reset your password. If necessary, you can also click the link at the bottom of the dialog box to create a new account.\n",
            "You: how to update ptc server\n",
            "Bot: \n",
            "To update the PTC License Server, you can use the following workflow: \n",
            "1. Make note of the product code that you have received via e-mail or use the PTC License Management Webtool to request for a license file via email. Save the license file in an ASCII format to a secure location on your disk. \n",
            "2. Start PTC Creo Installation Assistant from the mounted installation media (thumbdrive) or from the installation package downloaded from the Web. The Welcome screen appears. \n",
            "3. Click Setup license and then click Next. The License Identification screen appears. \n",
            "4. Type your new product code or Sales Order Number in the respective textbox and click Install Licensing. Alternatively, drag and drop your new license file into the Source column of the License Sources area. \n",
            "5. If a license server is already installed or running, the Assistant replaces the existing license file with the new one. If a license server is not running, the Assistant checks whether the new license file requires a license server. If so, the license server is automatically downloaded and installed. \n",
            "6. Click Finish. The Assistant restarts PTC License Server. For Triad configurations, two of the three partner machines must be running before licenses\n",
            "You: where is software installed\n",
            "Bot: \n",
            "Software is installed in the default path C:\\Program Files\\PTC\\Creo <version number>, where <version number> has the format V.R.M.C, where V indicates the main release number, R indicates the point release number, M indicates the maintenance release number, and C indicates the critical patch set number.\n",
            "You: bye\n",
            "Bot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Swap out your index below for whatever knowledge base you want\n",
        "bot = Chatbot(\"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\", index=index)\n",
        "bot.load_chat_history(\"chat_history.json\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"bye\", \"goodbye\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        bot.save_chat_history(\"chat_history.json\")\n",
        "        break\n",
        "    response = bot.generate_response(user_input)\n",
        "    print(f\"Bot: {response['content']}\")"
      ],
      "id": "24576df3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbgGQXpKierO"
      },
      "outputs": [],
      "source": [],
      "id": "QbgGQXpKierO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GXauMNugFT1l"
      },
      "id": "GXauMNugFT1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQcoUc0SFT41"
      },
      "id": "wQcoUc0SFT41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_contents(docs):\n",
        "    contents = \"\"\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        contents += f\"Document #{i}:\\n{doc.page_content}\\n\\n\"\n",
        "    return contents"
      ],
      "metadata": {
        "id": "JO2V4FutFT8C"
      },
      "id": "JO2V4FutFT8C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "1ku3hDR6FWax"
      },
      "id": "1ku3hDR6FWax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fbGDwv1GrXl",
        "outputId": "30a5288f-0559-4dc0-c47e-f5f5c59a51ef"
      },
      "id": "3fbGDwv1GrXl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.3.25-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Collecting requests>=2.28 (from chromadb)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.7)\n",
            "Collecting hnswlib>=0.7 (from chromadb)\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb)\n",
            "  Downloading clickhouse_connect-0.5.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.7/922.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Collecting fastapi>=0.85.1 (from chromadb)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.85.1->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2122032 sha256=1367670c0c4a2c3836893942438cde75b32869417b59850d89bc66ea721b6338\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: tokenizers, zstandard, websockets, uvloop, uvicorn, requests, python-dotenv, overrides, lz4, humanfriendly, httptools, hnswlib, watchfiles, starlette, posthog, coloredlogs, clickhouse-connect, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.3.25 clickhouse-connect-0.5.25 coloredlogs-15.0.1 fastapi-0.95.2 hnswlib-0.7.0 httptools-0.5.0 humanfriendly-10.0 lz4-4.3.2 onnxruntime-1.15.0 overrides-7.3.1 posthog-3.0.1 python-dotenv-1.0.0 requests-2.31.0 starlette-0.27.0 tokenizers-0.13.3 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set persist directory\n",
        "persist_directory = 'db'\n",
        "\n",
        "buffett_loader = DirectoryLoader('./docs/', glob=\"*.pdf\")\n",
        "buffett_docs = buffett_loader.load()\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=8)\n",
        "\n",
        "# Split documents and generate embeddings\n",
        "buffett_docs_split = text_splitter.split_documents(buffett_docs)\n",
        "\n",
        "# Create Chroma instances and persist embeddings\n",
        "buffettDB = Chroma.from_documents(buffett_docs_split, embeddings, persist_directory=os.path.join(persist_directory, 'buffett'))\n",
        "buffettDB.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56thzjwxF-ML",
        "outputId": "fd4d8021-4ff3-44a3-817d-fa5c963bc763"
      },
      "id": "56thzjwxF-ML",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 2094, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 684, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 538, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 400, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1732, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 302, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 593, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 321, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 316, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 440, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 267, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 273, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 310, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 340, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 336, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 299, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 260, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 264, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 429, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 342, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 425, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 377, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 335, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 375, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 369, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 286, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 355, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 271, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 342, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 269, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 277, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 440, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 269, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 255, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 319, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 315, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 300, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 293, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 355, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 298, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 343, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 269, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 258, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 272, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 259, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 262, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 260, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 295, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 343, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 474, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 311, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 290, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 282, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 296, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 386, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 298, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 266, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 311, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 263, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 261, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 377, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 271, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 336, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 306, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 256, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 351, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 384, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 303, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 294, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 434, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 288, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 366, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 272, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 320, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 261, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 324, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5359, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5282, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 6217, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2493, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3648, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5806, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 6127, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5930, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 6006, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 696, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5504, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2266, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1705, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 635, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 988, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 446, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 639, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 554, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 753, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 552, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 428, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1069, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 657, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1123, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 345, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 505, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 651, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1935, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 674, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1179, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 415, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 455, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 423, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 495, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 267, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 289, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 306, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 928, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 611, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 257, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 465, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 265, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 445, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 251, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 272, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 356, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 419, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 488, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 286, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 294, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 418, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 399, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 442, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 264, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 299, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 469, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 503, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 304, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 293, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 405, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 675, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 273, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 308, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 283, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 364, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 321, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 360, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 267, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 923, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 292, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 491, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 852, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 297, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 266, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 360, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 259, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 295, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 313, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 325, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 410, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 465, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1016, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 432, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 353, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 321, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 346, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 570, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 430, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 347, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 361, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 431, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 338, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 429, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 281, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 300, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2246, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 394, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 297, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 716, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 400, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 300, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1303, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 962, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 378, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 334, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 540, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 552, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 376, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 320, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 381, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 548, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 284, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 537, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 506, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 663, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 344, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 476, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 826, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 281, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 282, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 309, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 372, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 750, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 341, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 429, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 460, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 619, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 384, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 348, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 372, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3643, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1119, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 654, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 888, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 856, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 264, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 614, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 362, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 336, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 277, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 469, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 432, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1077, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 953, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 418, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 616, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 352, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 263, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 292, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 487, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 305, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 452, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 309, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 284, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 289, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 307, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 530, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 276, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 444, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 260, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 373, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 274, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 291, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 304, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 383, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 371, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 441, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 557, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 391, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 304, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 405, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 420, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 297, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 263, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 308, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 431, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 317, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1105, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 647, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 491, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 293, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 501, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 640, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 458, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 338, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1931, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 259, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 749, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 388, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 281, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 323, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 871, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 632, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 533, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 286, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 456, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 577, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 411, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 416, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 626, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 563, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 281, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 288, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 290, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 285, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 283, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 251, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 334, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 312, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 797, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 283, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 314, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 446, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 278, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 445, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 928, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 277, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 625, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 447, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 927, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 933, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 906, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 370, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 374, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 285, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 336, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 439, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1342, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1467, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 490, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1021, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1561, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1105, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 340, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1668, which is longer than the specified 250\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1018, which is longer than the specified 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Load the Buffett and Branson databases\n",
        "buffettDB = Chroma(persist_directory=os.path.join('db', 'buffett'), embedding_function=embeddings)\n",
        "buffett_retriever = buffettDB.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "def helper(query):\n",
        "    # Get relevant documents from Buffett's database\n",
        "    relevant_docs = buffett_retriever.get_relevant_documents(query)\n",
        "\n",
        "    # Use the provided function to prepare the context\n",
        "    context = get_page_contents(relevant_docs)\n",
        "    #print(context)\n",
        "    return context"
      ],
      "metadata": {
        "id": "Yk6B4Jk3HUEX"
      },
      "id": "Yk6B4Jk3HUEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"bye\", \"goodbye\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "    response = helper(user_input)\n",
        "    print(f\"Bot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "WrUlbKnwHjNY",
        "outputId": "a3e8a644-5f90-461c-faad-d24ac541a3f9"
      },
      "id": "WrUlbKnwHjNY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: how to install creo\n",
            "Bot: Document #1:\n",
            "7. Click Next.\n",
            "\n",
            "8. Customize Creo using the steps that follow, or click Install to start a simple\n",
            "\n",
            "installation.\n",
            "\n",
            "Document #2:\n",
            "7. Click Next.\n",
            "\n",
            "8. Customize Creo using the steps that follow, or click Install to start a simple\n",
            "\n",
            "installation.\n",
            "\n",
            "Document #3:\n",
            "7. Click Next.\n",
            "\n",
            "8. Customize Creo using the steps that follow, or click Install to start a simple\n",
            "\n",
            "installation.\n",
            "\n",
            "\n",
            "You: what are engineering features\n",
            "Bot: Document #1:\n",
            "Engineering Features\n",
            "\n",
            "Document #2:\n",
            "Engineering Features\n",
            "\n",
            "Document #3:\n",
            "Engineering Features\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2aa4a987a914>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"goodbye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bot: Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wymSTOhHF-_y"
      },
      "id": "wymSTOhHF-_y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CobJGjfF_Kb"
      },
      "id": "1CobJGjfF_Kb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKzMharGF_UT"
      },
      "id": "AKzMharGF_UT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}